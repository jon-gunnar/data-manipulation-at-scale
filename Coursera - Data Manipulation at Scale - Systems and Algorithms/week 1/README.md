# First week's assignments and solutions

## Problem 1: Get Twitter Data

We were required to mine tweets using Twitter's REST API.

Solution: [week 1/twitterstream.py](https://github.com/jon-gunnar/data-manipulation-at-scale/blob/master/week%201/twitterstream.py)  
Outcome: [week 1/output.txt](https://github.com/jon-gunnar/data-manipulation-at-scale/blob/master/week%201/output.txt)

## Problem 2: Derive the sentiment of each tweet

We were required to calculate sentiment scores for tweets based on a list of terms with precalculated sentiment values ([AFINN-111.txt](https://github.com/jon-gunnar/data-manipulation-at-scale/blob/master/week%201/AFINN-111.txt)).

Solution: [week 1/tweetsentiment.py](https://github.com/jon-gunnar/data-manipulation-at-scale/blob/master/week%201/tweetsentiment.py)  

## Problem 3: Derive the sentiment of new terms

We were required to calculate sentiment values for words that are not listed in [AFINN-111.txt](https://github.com/jon-gunnar/data-manipulation-at-scale/blob/master/week%201/AFINN-111.txt) based on the context they appear in.

Solution: [week 1/termsentiment.py](https://github.com/jon-gunnar/data-manipulation-at-scale/blob/master/week%201/termsentiment.py)

## Problem 4: Compute Term Frequency

We were required to calculate the frequency of all words in all the tweets.

Solution: [week 1/frequency.py](https://github.com/jon-gunnar/data-manipulation-at-scale/blob/master/week%201/frequency.py)

## Problem 5: Which State is happiest?

We were required to determine the US state with most positive tweets.

Solution: [week 1/happieststate.py](https://github.com/jon-gunnar/data-manipulation-at-scale/blob/master/week%201/happieststate.py)

## Problem 6: Top ten hash tags

We were required to find ten most frequently used hashtags.

Solution: [week 1/toptenhashtags.py](https://github.com/jon-gunnar/data-manipulation-at-scale/blob/master/week%201/toptenhashtags.py)
